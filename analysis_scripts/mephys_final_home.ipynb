{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import logging\n",
    "#from functions_py.mephys_funcs import read_file, merge_dataframes, filter_date, drop_cols, drop_nans, \\\n",
    "#create_cond_df, create_container_df, filter_df\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(context = \"notebook\", style = \"ticks\", font=\"verdana\") # font_scale = 1.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logging Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas Display Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",150) #Expands the number of characters shown in the columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lists/Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_jem = [\"date\", \"organism_name\", \"container\", \"rigOperator\", \"status\", \"roi\",\n",
    "              \"extraction.postPatch\", \"extraction.endPipetteR\"]\n",
    "fields_ephys = [\"name\", \"vrest\", \"ri\", \"sag\", \n",
    "                \"tau\", \"upstroke_downstroke_ratio_long_square\", \"latency\", \"f_i_curve_slope\"]\n",
    "fields_shiny = [\"patch.date\", \"cell_name\", \"sample_id\", \"cell_specimen_project\",\n",
    "                \"subclass_label\", \"topLeaf_label\", \"broad_class_label\", \"VISp_cluster\",\n",
    "                \"marker_sum_norm_label\", \"Norm_Marker_Sum.0.4_label\", \"Tree_call\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_jem = \"Z:/Patch-Seq/compiled-jem-data/jem_metadata.csv\"\n",
    "#path_shiny = \"//allen/programs/celltypes/workgroups/rnaseqanalysis/shiny/patch_seq/star/mouse_patchseq_VISp_current/mapping.df.with.bp.40.lastmap.csv\"\n",
    "\n",
    "path_jem = \"C:/Users/kumar/Documents/GitHub/analysis_projects/csv/jem_metadata_wFAILURE.csv\"\n",
    "path_ephys = \"C:/Users/kumar/Documents/GitHub/analysis_projects/csv/ephys_mIVSCC_MET.csv\"\n",
    "path_shiny = \"C:/Users/kumar/Documents/GitHub/analysis_projects/csv/Mouse_VISp_ctx_shiny.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_users = [\"kristenh\", \"lindsayn\", \"ramr\", \"katherineb\", \"jessicat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_colors={\"RSP\": \"#a1d99b\", \"VISp\": \"#9ecae1\"}\n",
    "s_colors={\"RSP\": \"#41ab5d\", \"VISp\": \"#4292c6\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, fields=None):\n",
    "    \"\"\"Reads file in as pandas dataframe by using pd.read_csv\n",
    "    Args:\n",
    "        path: path of file location\n",
    "    Return:\n",
    "        df: a pandas dataframe\n",
    "    \"\"\"\n",
    "    global df\n",
    "    df = pd.read_csv(path, usecols=fields)\n",
    "    LOGGER.info(\"Read file in as a pandas dataframe\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(left_df, right_df, left_col, right_col, join_how):\n",
    "    \"\"\"Merges two dataframes together into one dataframe\n",
    "    Args:\n",
    "        left_df: a pandas dataframe on the left\n",
    "        right_df: a pandas dataframe on the right\n",
    "        left_col: a column from the left dataframe\n",
    "        right_col: a column from the right dataframe\n",
    "    Return:\n",
    "        merge_df: a merged pandas dataframe\n",
    "    \"\"\"\n",
    "    merge_df = pd.merge(left = left_df,\n",
    "                        right = right_df,\n",
    "                        left_on = left_col,\n",
    "                        right_on = right_col, \n",
    "                        how = join_how)\n",
    "    LOGGER.info(\"Merged two pandas dataframe into one dataframe\")\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df, drop_col):\n",
    "    \"\"\"Drop unnessary columns from dataframe\n",
    "    Args:\n",
    "        df: a pandas dataframe\n",
    "        drop_col(lst): column names to drop from dataframe\n",
    "    Return:\n",
    "        df: a pandas dataframe without certain columns\n",
    "    \"\"\"\n",
    "    LOGGER.info(\"Dropped columns: %s\", drop_col)\n",
    "    df.drop(columns=drop_col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nans(df, drop_na_col):\n",
    "    \"\"\"Drop Nans from selected columns\n",
    "    Args:\n",
    "        df: a pandas dataframe\n",
    "        drop_na_col(lst): column names to drop NaNs from \n",
    "    Return:\n",
    "        df: a pandas dataframe without NaNs in certain columns\n",
    "    \"\"\"\n",
    "    LOGGER.info(\"Dropped NaNs from these columns: %s\", drop_na_col)\n",
    "    df.dropna(subset=drop_na_col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date_range(df, date_col):\n",
    "    \"\"\"Filters and sorts the date column by specific date range in the dataframe.\n",
    "    Args:\n",
    "        df: a pandas dataframe\n",
    "        date_col(string): column name with date information\n",
    "    Returns:\n",
    "        df: a pandas dataframe with a filtered date range\n",
    "    \"\"\"\n",
    "    start_date = \"2019-01-01\"\n",
    "    end_date = \"2020-12-31\"\n",
    "\n",
    "    mask = (df[date_col] > start_date) & (df[date_col] <= end_date)\n",
    "    df = df.loc[mask]\n",
    "    df.sort_values([date_col], inplace=True)\n",
    "    LOGGER.info(\"Filtered dataframe to only display 2019-2020 data\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, fil_col, fil_val):\n",
    "    \"\"\"Creates a dataframe based on values from a single column\n",
    "     Args:\n",
    "        df: a pandas dataframe\n",
    "        fil_col(string): column name from dataframe\n",
    "        fil_val(string): values to restrict dataframe by\n",
    "    Return:\n",
    "        df: a pandas dataframe created by values from a single column\n",
    "    \"\"\"\n",
    "    df = df[df[fil_col] == fil_val]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_container_df(df, container_col):\n",
    "    \"\"\"Creates container label based on original container column\n",
    "    Args:\n",
    "        df: a pandas dataframe\n",
    "        container_col: a column name with the container label information\n",
    "    Return:\n",
    "        df: a pandas dataframe with a new column with container labels\n",
    "    \"\"\"\n",
    "    df[\"container_label\"] = df[container_col].str[0:2]\n",
    "    LOGGER.info(\"Created a container_label column to show(ex.'PA')\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cond_df(df, col, val):\n",
    "    \"\"\"Creates a dataframe based on values from a single column\n",
    "     Args:\n",
    "        df: a pandas dataframe\n",
    "        col(string): column name from dataframe\n",
    "        val(list): values to restrict dataframe by\n",
    "    Return:\n",
    "        df: a pandas dataframe created by values from a single column\n",
    "    \"\"\"\n",
    "    df = df[df[col].str.contains(\"|\".join(val))]\n",
    "    LOGGER.info(\"Created a conditional dataframe based on a list of values\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "INFO:__main__:Filtered dataframe to only display 2019-2020 data\n",
      "INFO:__main__:Filtered dataframe to only display 2019-2020 data\n"
     ]
    }
   ],
   "source": [
    "jem = read_file(path_jem, fields_jem) #20843 rows\n",
    "ephys = read_file(path_ephys, fields_ephys) #8541 rows\n",
    "shiny = read_file(path_shiny, fields_shiny) #10674 rows\n",
    "\n",
    "jem = filter_df(jem, \"status\", \"SUCCESS\") #13325 rows\n",
    "jem = filter_date_range(jem, \"date\") #6335 rows\n",
    "shiny = filter_date_range(shiny, \"patch.date\") #3050 rows\n",
    "\n",
    "merge_sj = merge_dataframes(shiny, jem, \"sample_id\", \"container\", \"inner\") #3051 rows (even if how=left)\n",
    "merge_all = merge_dataframes(merge_sj, ephys, \"cell_name\", \"name\", \"inner\") #2787 rows\n",
    "\n",
    "merge_all = create_container_df(merge_all, \"container\")\n",
    "\n",
    "drop_nans_list = [\"date\"]\n",
    "merge_all = drop_nans(merge_all, drop_nans_list)\n",
    "\n",
    "drop_cols_list = [\"sample_id\", \"patch.date\", \"status\", \"name\", \"cell_specimen_project\", \"organism_name\"]\n",
    "merge_all = drop_cols(merge_all, drop_cols_list)\n",
    "\n",
    "merge_all.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:/Users/kumar/Documents/Github/analysis_projects/csv/\"\n",
    "excel_path = \"C:/Users/kumar/Documents/Github/analysis_projects/excel/\"\n",
    "plot_path = \"C:/Users/kumar/Documents/Github/analysis_projects/plot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(excel_path + \"mephys_final_home.xlsx\")\n",
    "merge_all.to_excel(writer, \"All\", freeze_panes=(1,0))\n",
    "merge_sj.to_excel(writer, \"Shiny_Jem\", freeze_panes=(1,0))\n",
    "shiny.to_excel(writer, \"Shiny\", freeze_panes=(1,0))\n",
    "jem.to_excel(writer, \"Jem\", freeze_panes=(1,0))\n",
    "ephys.to_excel(writer, \"Ephys\", freeze_panes=(1,0))\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Region Specific dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'roi_major'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'roi_major'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-16a245079314>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrsp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_cond_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"roi_major\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"RSPd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"RSPv\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mssp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_cond_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"roi_major\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"SSp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0morb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_cond_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"roi_major\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"ORB\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mctxsp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_cond_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"roi_major\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"CTXsp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_cond_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"roi_major\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"MOp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MOs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-37376efffe35>\u001b[0m in \u001b[0;36mcreate_cond_df\u001b[1;34m(df, col, val)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mby\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mLOGGER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Created a conditional dataframe based on a list of values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'roi_major'"
     ]
    }
   ],
   "source": [
    "rsp = create_cond_df(merge_all, \"roi_major\", [\"RSPd\", \"RSPv\"])\n",
    "ssp = create_cond_df(merge_all, \"roi_major\", [\"SSp\"])\n",
    "orb = create_cond_df(merge_all, \"roi_major\", [\"ORB\"])\n",
    "ctxsp = create_cond_df(merge_all, \"roi_major\", [\"CTXsp\"])\n",
    "mo = create_cond_df(merge_all, \"roi_major\", [\"MOp\", \"MOs\"])\n",
    "visp = create_cond_df(merge_all, \"roi_major\", [\"VISp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-f5ee9edf6726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmerge_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"roi\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mmerge_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"roi\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"VISp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"VISp\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Other\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1553\u001b[0m             \u001b[1;34m\"The truth value of a {0} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m             \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\".format(\n\u001b[1;32m-> 1555\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m             )\n\u001b[0;32m   1557\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "for x in merge_all[\"roi\"]:\n",
    "    if merge_all[\"roi\"].str.contains(\"VISp\"):\n",
    "        x = \"VISp\"\n",
    "    else:\n",
    "        x = \"Other\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary \n",
    "rig_user_dictionary ={'rig_user_name' : \"P1\", 'Poetry' : 800, 'Comedy' : 1200} \n",
    "  \n",
    "# Add a new column named 'Price' \n",
    "df[\"container_label\"] = df[\"rigOperator\"].map(rig_user_dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df['Event']:\n",
    "     if x =='Music':\n",
    "        x = 1500\n",
    "    else:\n",
    "        x = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
